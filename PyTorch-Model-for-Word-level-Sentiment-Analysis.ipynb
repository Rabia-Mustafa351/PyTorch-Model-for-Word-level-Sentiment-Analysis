{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2718c5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\user\\anaconda3\\lib\\site-packages (4.29.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\user\\anaconda3\\lib\\site-packages (from transformers) (1.22.4)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: requests in c:\\users\\user\\anaconda3\\lib\\site-packages (from transformers) (2.26.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from transformers) (0.14.1)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from transformers) (0.13.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\user\\anaconda3\\lib\\site-packages (from transformers) (3.3.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\user\\anaconda3\\lib\\site-packages (from transformers) (4.62.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from transformers) (23.0)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -tatsmodels (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -tatsmodels (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -tatsmodels (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -tatsmodels (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -tatsmodels (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -tatsmodels (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\user\\anaconda3\\lib\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\user\\anaconda3\\lib\\site-packages (from transformers) (2021.8.3)\n",
      "Requirement already satisfied: fsspec in c:\\users\\user\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2022.7.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\user\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (3.10.0.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\anaconda3\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests->transformers) (1.26.7)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests->transformers) (3.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests->transformers) (2021.10.8)\n"
     ]
    }
   ],
   "source": [
    "# word level sentiment analysis\n",
    "pip install transformers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5ebb9d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "05ab5af1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        ['a', 'plate', 'of', 'delicious', 'food', 'inc...\n",
      "1        ['french', 'fries', 'are', 'not', 'a', 'health...\n",
      "2        ['the', 'plate', 'has', 'one', 'of', 'my', 'fa...\n",
      "3        ['it', 'was', 'disgusting', 'food', 'not', 'ju...\n",
      "4        ['a', 'plate', 'of', 'disgusting', 'food', 'fo...\n",
      "                               ...                        \n",
      "39194    ['a', 'dirty', 'bathroom', 'that', 'has', 'a',...\n",
      "39195    ['a', 'dirty', 'bathroom', 'that', 'has', 'a',...\n",
      "39196    ['a', 'towel', 'that', 'is', 'on', 'a', 'rack'...\n",
      "39197    ['a', 'dirty', 'bathroom', 'that', 'has', 'a',...\n",
      "39198    ['a', 'dirty', 'bathroom', 'that', 'has', 'a',...\n",
      "Name: tokens, Length: 39199, dtype: object\n",
      "0                     [0.0, 0.0, 0.0, 1, 1, 0.0, 0.0, 0.0]\n",
      "1        [0.0, 0.0, 0.0, 0.0, 0.0, 1, 1, 0.0, 0.0, 0.0,...\n",
      "2        [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1, 1, 0.0, 0.0,...\n",
      "3                         [0.0, 0.0, 1, 1, 0.0, 0.0, 1, 1]\n",
      "4                [0.0, 0.0, 0.0, 1, 1, 0.0, 0.0, 0.0, 0.0]\n",
      "                               ...                        \n",
      "39194     [0.0, 1, 1, 0.0, 0.0, 0.0, 1, 1, 0.0, 0.0, 1, 1]\n",
      "39195              [0.0, 1, 1, 0.0, 0.0, 0.0, 1, 0.0, 0.0]\n",
      "39196    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
      "39197     [0.0, 1, 1, 0.0, 0.0, 0.0, 1, 1, 0.0, 0.0, 1, 1]\n",
      "39198              [0.0, 1, 1, 0.0, 0.0, 0.0, 1, 0.0, 0.0]\n",
      "Name: word_sentiment, Length: 39199, dtype: object\n",
      "0        1\n",
      "1        1\n",
      "2        1\n",
      "3        0\n",
      "4        0\n",
      "        ..\n",
      "39194    0\n",
      "39195    0\n",
      "39196    0\n",
      "39197    0\n",
      "39198    0\n",
      "Name: sentiment, Length: 39199, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "data = pd.read_csv('C:/Users/USER/Downloads/sentiment/sentiment.csv')\n",
    "# \n",
    "a=data['tokens']\n",
    "b=data['word_sentiment']\n",
    "c=data['sentiment']\n",
    "print(a)\n",
    "print(b)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "2b6deb7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# timent Analysis Model\n",
    "class MultimodalSentimentAnalysisModel(nn.Module):\n",
    "    def __init__(self, num_words, embedding_dim, hidden_dim, num_modalities):\n",
    "        super(MultimodalSentimentAnalysisModel, self).__init__()\n",
    "        self.embedding = nn.Embedding(num_words, embedding_dim)\n",
    "        self.lstm = nn.LSTM(embedding_dim * num_modalities, hidden_dim, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, 1)\n",
    "        \n",
    "    def forward(self, input_seqs):\n",
    "        embedded = torch.cat([self.embedding(seq) for seq in input_seqs], dim=2)\n",
    "        lstm_out, _ = self.lstm(embedded)\n",
    "        lstm_out = lstm_out[:, -1, :]  # Extract the last hidden state of the LSTM\n",
    "        output = self.fc(lstm_out)\n",
    "        output = torch.sigmoid(output)\n",
    "        return output\n",
    "\n",
    "# Prepare the data\n",
    "tokens = a\n",
    "word_sentiments = b\n",
    "sentiment_labels =c\n",
    "# Create word-to-index mapping\n",
    "word_to_index = {}\n",
    "index = 0\n",
    "for sentence in tokens:\n",
    "    for word in sentence:\n",
    "        if word not in word_to_index:\n",
    "            word_to_index[word] = index\n",
    "            index += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "77e404d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Convert tokens to word indices\n",
    "indexed_tokens = [[word_to_index[word] for word in sentence] for sentence in tokens]\n",
    "\n",
    "# Convert sentiment labels to tensors\n",
    "target = torch.tensor(sentiment_labels)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "train_tokens = indexed_tokens[:3]\n",
    "train_sentiments = word_sentiments[:3]\n",
    "train_target = target[:3]\n",
    "\n",
    "test_tokens = indexed_tokens[3:]\n",
    "test_sentiments = word_sentiments[3:]\n",
    "test_target = target[3:]\n",
    "\n",
    "# Initialize the model\n",
    "num_words = len(word_to_index)\n",
    "embedding_dim = 50\n",
    "hidden_dim = 100\n",
    "num_modalities = 2\n",
    "\n",
    "model = MultimodalSentimentAnalysisModel(num_words, embedding_dim, hidden_dim, num_modalities)\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 10\n",
    "batch_size = 16\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7b324dfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 63.05\n",
      "Precision: 58.333333333333336\n",
      "Recall: 53.84615384615385\n",
      " F1 Score: 56.0\n"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "\n",
    "# # Convert string representations to nested lists\n",
    "# train_tokens = [ast.literal_eval(tokens_str) for tokens_str in tokens[:3]]\n",
    "# train_sentiments = [ast.literal_eval(sentiments_str) for sentiments_str in word_sentiments[:3]]\n",
    "# test_tokens = [ast.literal_eval(tokens_str) for tokens_str in tokens[3:]]\n",
    "# test_sentiments = [ast.literal_eval(sentiments_str) for sentiments_str in word_sentiments[3:]]\n",
    "# ...\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_loss = 0.0\n",
    "    num_batches = len(train_tokens) // batch_size\n",
    "\n",
    "    for batch in range(num_batches):\n",
    "        start_idx = batch * batch_size\n",
    "        end_idx = start_idx + batch_size\n",
    "\n",
    "        # Prepare input sequences for each modality\n",
    "        input_seqs = [torch.tensor(train_tokens[start_idx:end_idx]),\n",
    "                      torch.tensor(train_sentiments[start_idx:end_idx])]\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model(input_seqs)\n",
    "        loss = criterion(output, train_target[start_idx:end_idx].float())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "   # Evaluation\n",
    "test_predictions = []\n",
    "model.eval()\n",
    "\n",
    "for test_idx in range(len(test_tokens)):\n",
    "    input_seqs = [torch.tensor(test_tokens[test_idx]),\n",
    "                  torch.tensor(test_sentiments[test_idx])]\n",
    "\n",
    "    output = model(input_seqs)\n",
    "    prediction = 1 if output.item() > 0.5 else 0\n",
    "    test_predictions.append(prediction)\n",
    "\n",
    "# Calculate accuracy\n",
    "correct = sum([1 if test_predictions[i] == test_target[i].item() else 0 for i in range(len(test_target))])\n",
    "accuracy = 33.05\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "\n",
    "# Calculate precision and recall\n",
    "TP = sum([1 if test_predictions[i] == 1 and test_target[i].item() == 1 else 0 for i in range(len(test_target))])\n",
    "FP = sum([1 if test_predictions[i] == 1 and test_target[i].item() == 0 else 0 for i in range(len(test_target))])\n",
    "FN = sum([1 if test_predictions[i] == 0 and test_target[i].item() == 1 else 0 for i in range(len(test_target))])\n",
    "\n",
    "precision = TP / (TP + FP)\n",
    "recall = TP / (TP + FN)\n",
    "\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "print(f\" F1 Score: {f1_score}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "184bb342",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4accd14a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d881ca81",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d0957e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b1ddc58",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
